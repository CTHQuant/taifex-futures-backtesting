{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9be9e7-28e8-4cd2-a033-d8cf7aa266b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shioaji as sj\n",
    "\n",
    "with open('API.json', 'r', encoding='utf-8') as f:\n",
    "    s = json.load(f)\n",
    "api = sj.Shioaji(simulation=True)\n",
    "accounts = api.login(api_key=s['api_key'], secret_key=s['secret_key'])\n",
    "accounts_ca = api.activate_ca(s['ca_path'], s['ca_passwd'], s['person_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4ffc2-499d-42f7-841a-b309b436dc07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "from collections import deque\n",
    "from datetime import datetime, timedelta, time as dt_time\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from shioaji import Shioaji\n",
    "\n",
    "# ===== 抓取資料 =====\n",
    "# 資料設定\n",
    "FETCH_TYPE    = \"TICKS\"  # \"KBARS\"/\"TICKS\"/\"BOTH\"\n",
    "FETCH_FUTURES = True\n",
    "START_DATE    = \"2024-03-12\"\n",
    "END_DATE      = \"2024-03-29\"\n",
    "contract      = api.Contracts.Futures.TXF.TXFR1\n",
    "STOCKS_TO_FETCH = [\"2330\", \"2454\", \"2317\", \"2881\", \"2412\", \"2382\", \"2308\", \"2882\", \"2891\", \"3711\"]\n",
    "SAVE_DIR      = r\"C:\\Users\\USER\\Desktop\\雲端同步\\Shioaji\\Backtesting\"\n",
    "# ===== 速率限制器與全域計數設定 =====\n",
    "class RateLimiter:\n",
    "    def __init__(self, limit, window):\n",
    "        self.limit = limit\n",
    "        self.window = window\n",
    "        self.calls = deque()\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def acquire(self):\n",
    "        with self.lock:\n",
    "            now = time.time()\n",
    "            while self.calls and now - self.calls[0] > self.window:\n",
    "                self.calls.popleft()\n",
    "            if len(self.calls) >= self.limit:\n",
    "                sleep_t = self.window - (now - self.calls[0]) + 0.01\n",
    "                time.sleep(sleep_t)\n",
    "                now = time.time()\n",
    "                while self.calls and now - self.calls[0] > self.window:\n",
    "                    self.calls.popleft()\n",
    "            self.calls.append(now)\n",
    "\n",
    "limiters = {\n",
    "    'market': RateLimiter(limit=50, window=5),  \n",
    "    'account': RateLimiter(limit=25, window=5),  \n",
    "    'order': RateLimiter(limit=250, window=10),  \n",
    "}\n",
    "\n",
    "market_limits = {\n",
    "    'ticks': 10,   \n",
    "    'kbars': 50, \n",
    "}\n",
    "market_counts = {k: 0 for k in market_limits}\n",
    "\n",
    "daily_limits = {\n",
    "    'login': 1000,\n",
    "    'kbars': 1000\n",
    "}\n",
    "\n",
    "daily_counts = {k: 0 for k in daily_limits}\n",
    "\n",
    "max_connections = 5\n",
    "current_connections = 0\n",
    "conn_lock = threading.Lock()\n",
    "\n",
    "max_subscriptions = 200\n",
    "subscription_count = 0\n",
    "sub_lock = threading.Lock()\n",
    "\n",
    "def is_trading_hours():\n",
    "    now = datetime.now().time()\n",
    "    return dt_time(9, 0) <= now <= dt_time(13, 30)\n",
    "\n",
    "ENDPOINT_GROUP = {\n",
    "    'credit_enquires': 'market',\n",
    "    'short_stock_sources': 'market',\n",
    "    'snapshots': 'market',\n",
    "    'ticks': 'market',\n",
    "    'kbars': 'market',\n",
    "    'list_profit_loss_detail': 'account',\n",
    "    'account_balance': 'account',\n",
    "    'list_settlements': 'account',\n",
    "    'list_profit_loss': 'account',\n",
    "    'list_positions': 'account',\n",
    "    'margin': 'account',\n",
    "    'place_order': 'order',\n",
    "    'update_status': 'order',\n",
    "    'cancel_order': 'order',\n",
    "}\n",
    "\n",
    "# 包裝 API 方法：檢查方法是否存在，並進行速率限制\n",
    "for name, grp in ENDPOINT_GROUP.items():\n",
    "    if hasattr(api, name): \n",
    "        orig = getattr(api, name)\n",
    "        def make_wrapper(func, endpoint, group):\n",
    "            def wrapper(*args, **kwargs):\n",
    "                limiters[group].acquire()\n",
    "        \n",
    "                if endpoint in ('ticks', 'kbars') and is_trading_hours():\n",
    "                    if endpoint not in market_counts:\n",
    "                        market_counts[endpoint] = 0\n",
    "                    if market_counts[endpoint] >= market_limits[endpoint]:\n",
    "                        raise RuntimeError(f\"{endpoint} 盤中次數已達上限\")\n",
    "                    market_counts[endpoint] += 1\n",
    "        \n",
    "                return func(*args, **kwargs)\n",
    "            return wrapper\n",
    "        setattr(api, name, make_wrapper(orig, name, grp))\n",
    "    else:\n",
    "        print(f\"方法 {name} 不存在於 API 中\")\n",
    "\n",
    "# ===== 資料檢查 =====\n",
    "def load_existing(path, date_col):\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_parquet(path)\n",
    "        existing = set(df[date_col].dt.date.astype(str))\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "        existing = set()\n",
    "    return df, existing\n",
    "\n",
    "kbars_df, existing_kbar_dates = load_existing(\n",
    "    os.path.join(SAVE_DIR, \"txf_kbars.parquet\"), 'ts'\n",
    ")\n",
    "ticks_df, existing_tick_dates = load_existing(\n",
    "    os.path.join(SAVE_DIR, \"txf_ticks.parquet\"), 'ts'\n",
    ")\n",
    "stock_exist = {}\n",
    "for sid in STOCKS_TO_FETCH:\n",
    "    _, exist = load_existing(os.path.join(SAVE_DIR,f\"stock_kbars_{sid}.parquet\"), 'ts')\n",
    "    stock_exist[sid] = exist\n",
    "\n",
    "# 建日期列表\n",
    "dates = []\n",
    "s = datetime.strptime(START_DATE,\"%Y-%m-%d\")\n",
    "e = datetime.strptime(END_DATE,  \"%Y-%m-%d\")\n",
    "while s <= e:\n",
    "    dates.append(s.strftime(\"%Y-%m-%d\"))\n",
    "    s += timedelta(days=1)\n",
    "\n",
    "# ===== 抓取函式 =====\n",
    "def fetch_future(d):\n",
    "    res = {'date': d, 'kbar': None, 'tick': None}\n",
    "    if FETCH_FUTURES and FETCH_TYPE in (\"KBARS\", \"BOTH\") and d not in existing_kbar_dates:\n",
    "        k = api.kbars(contract=contract, start=d, end=d)\n",
    "        if k:\n",
    "            df = pd.DataFrame({**k})\n",
    "            df.ts = pd.to_datetime(df.ts)\n",
    "            res['kbar'] = df\n",
    "    if FETCH_FUTURES and FETCH_TYPE in (\"TICKS\", \"BOTH\") and d not in existing_tick_dates:\n",
    "        t = api.ticks(contract=contract, date=d)\n",
    "        if t:\n",
    "            df = pd.DataFrame({**t})\n",
    "            df.ts = pd.to_datetime(df.ts)\n",
    "            res['tick'] = df\n",
    "    return res\n",
    "\n",
    "def fetch_stock(sid, d):\n",
    "    if d in stock_exist[sid]:\n",
    "        return None\n",
    "    c = api.Contracts.Stocks.TSE[sid]\n",
    "    k = api.kbars(c, start=d, end=d)\n",
    "    if k:\n",
    "        df = pd.DataFrame({**k})\n",
    "        df.ts = pd.to_datetime(df.ts)\n",
    "        return df\n",
    "    return None\n",
    "\n",
    "# ===== 執行抓取 & 儲存 =====\n",
    "if FETCH_FUTURES:\n",
    "    new_kbars, new_ticks = [], []\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        futures = {executor.submit(fetch_future, d): d for d in dates}\n",
    "        for fut in as_completed(futures):\n",
    "            res = fut.result()\n",
    "            d = res['date']\n",
    "            if res['kbar'] is not None:\n",
    "                new_kbars.append(res['kbar'])\n",
    "                print(f\"[TXF] {d} kbars: {len(res['kbar'])}\")\n",
    "            else:\n",
    "                print(f\"[TXF] {d} kbars 已存在或無資料\")\n",
    "            if res['tick'] is not None:\n",
    "                new_ticks.append(res['tick'])\n",
    "                print(f\"[TXF] {d} ticks: {len(res['tick'])}\")\n",
    "            else:\n",
    "                print(f\"[TXF] {d} ticks 已存在或無資料\")\n",
    "    # 儲存期貨\n",
    "    if new_kbars:\n",
    "        df = pd.concat([kbars_df] + new_kbars).drop_duplicates('ts').sort_values('ts')\n",
    "        df.to_parquet(os.path.join(SAVE_DIR, \"txf_kbars.parquet\"), index=False)\n",
    "    if new_ticks:\n",
    "        df = pd.concat([ticks_df] + new_ticks).drop_duplicates('ts').sort_values('ts')\n",
    "        df.to_parquet(os.path.join(SAVE_DIR, \"txf_ticks.parquet\"), index=False)\n",
    "else:\n",
    "    print(\"已設定不抓取台指期資料 (FETCH_FUTURES=False)\")\n",
    "\n",
    "# 各股票 KBARS\n",
    "if FETCH_TYPE in (\"KBARS\", \"BOTH\"):\n",
    "    for sid in STOCKS_TO_FETCH:\n",
    "        stock_path = os.path.join(SAVE_DIR, f\"stock_kbars_{sid}.parquet\")\n",
    "        stock_df, _ = load_existing(stock_path, 'ts')\n",
    "        new_stock_kbars = []\n",
    "        with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "            futures = {executor.submit(fetch_stock, sid, d): d for d in dates}\n",
    "            for fut in as_completed(futures):\n",
    "                df = fut.result()\n",
    "                d = futures[fut]\n",
    "                if df is not None:\n",
    "                    new_stock_kbars.append(df)\n",
    "                    print(f\"[{sid}] {d} kbars: {len(df)}\")\n",
    "                else:\n",
    "                    print(f\"[{sid}] {d} 已存在或無資料\")\n",
    "        if new_stock_kbars:\n",
    "            merged = pd.concat([stock_df] + new_stock_kbars).drop_duplicates('ts').sort_values('ts')\n",
    "            merged.to_parquet(stock_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2af15de1-bb91-4e62-b7cc-c1aa9672a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datetime import datetime\n",
    "\n",
    "# 設定時間範圍\n",
    "EXPECTED_KBARS = 300\n",
    "\n",
    "# ===== 讀取 KBARS =====\n",
    "kbars_df = (\n",
    "    pl.read_parquet(\"txf_kbars.parquet\")\n",
    "    .filter(\n",
    "        (pl.col(\"ts\").dt.time() >= datetime.strptime(\"08:45\", \"%H:%M\").time()) &\n",
    "        (pl.col(\"ts\").dt.time() <= datetime.strptime(\"13:45\", \"%H:%M\").time())\n",
    "    )\n",
    "    .with_columns(pl.col(\"ts\").dt.date().alias(\"date\"))\n",
    "    .group_by(\"date\")\n",
    "    .agg(pl.len().alias(\"kbar_count\"))\n",
    ")\n",
    "\n",
    "# ===== 讀取 TICKS =====\n",
    "ticks_df = (\n",
    "    pl.read_parquet(\"txf_ticks.parquet\")\n",
    "    .filter(\n",
    "        (pl.col(\"ts\").dt.time() >= datetime.strptime(\"08:45\", \"%H:%M\").time()) &\n",
    "        (pl.col(\"ts\").dt.time() <= datetime.strptime(\"13:45\", \"%H:%M\").time())\n",
    "    )\n",
    "    .with_columns(pl.col(\"ts\").dt.date().alias(\"date\"))\n",
    "    .group_by(\"date\")\n",
    "    .agg(pl.len().alias(\"tick_count\"))\n",
    ")\n",
    "\n",
    "# ===== 合併比對 =====\n",
    "summary_df = (\n",
    "    kbars_df.join(ticks_df, on=\"date\", how=\"full\")\n",
    "    .with_columns([\n",
    "        (pl.col(\"kbar_count\") == EXPECTED_KBARS).fill_null(False).alias(\"kbar_ok\"),\n",
    "        (pl.col(\"tick_count\") > 0).fill_null(False).alias(\"tick_ok\"),\n",
    "    ])\n",
    "    .with_columns([\n",
    "        (pl.col(\"kbar_ok\") & pl.col(\"tick_ok\")).alias(\"both_ok\")\n",
    "    ])\n",
    "    .sort(\"date\")\n",
    ")\n",
    "\n",
    "# ===== 排序 + 輸出 CSV =====\n",
    "summary_df = summary_df.sort(\"date\")\n",
    "\n",
    "# 輸出為 CSV\n",
    "summary_df.write_csv(\"kbars_ticks_check_2024.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cf4f10a-b854-4fc1-9dbb-987499a9c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "\n",
    "STOCKS_TO_FETCH = [\"2330\", \"2454\", \"2317\", \"2881\", \"2412\", \"2382\", \"2308\", \"2882\", \"2891\", \"3711\"]\n",
    "SAVE_DIR = r\"C:\\Users\\USER\\Desktop\\雲端同步\\Shioaji\\Backtesting\"\n",
    "EXPECTED_COUNT = 300\n",
    "all_missing = []\n",
    "\n",
    "# 逐檔讀取並檢查\n",
    "for stock in STOCKS_TO_FETCH:\n",
    "    file_path = os.path.join(SAVE_DIR, f\"stock_kbars_{stock}.parquet\")\n",
    "    if not os.path.exists(file_path):\n",
    "        continue\n",
    "\n",
    "    df = (\n",
    "        pl.read_parquet(file_path)\n",
    "        .filter(\n",
    "            (pl.col(\"ts\").dt.time() >= datetime.strptime(\"09:00\", \"%H:%M\").time()) &\n",
    "            (pl.col(\"ts\").dt.time() <= datetime.strptime(\"13:30\", \"%H:%M\").time())\n",
    "        )\n",
    "        .with_columns(pl.col(\"ts\").dt.date().alias(\"date\"))\n",
    "        .group_by(\"date\")\n",
    "        .agg(pl.len().alias(\"count\"))\n",
    "        .filter(pl.col(\"count\") != EXPECTED_COUNT)\n",
    "        .with_columns(pl.lit(stock).alias(\"stock\"))\n",
    "    )\n",
    "    if df.height > 0:\n",
    "        all_missing.append(df)\n",
    "\n",
    "# 合併所有缺漏記錄\n",
    "if all_missing:\n",
    "    summary = pl.concat(all_missing).sort([\"date\", \"stock\"])\n",
    "    summary.write_csv(os.path.join(SAVE_DIR, \"缺漏報表.csv\"))\n",
    "else:\n",
    "    print(\" 所有檔案資料完整無缺漏\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d18c92e-47d7-4f85-aea6-53ddca782599",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.usage()\n",
    "api.logout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Shioaji]",
   "language": "python",
   "name": "shioaji"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
